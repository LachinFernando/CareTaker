from openai import OpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
import PyPDF2
import base64
import streamlit as st
import os
from pydantic import BaseModel, Field
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# environment variables
os.environ["OPENAI_API_KEY"] = st.secrets["llm"]["OPENAI_API_KEY"]

# constants
QA_MODEL = "gpt-4o-mini"
COMMON_TEMPLATE = """
You are a helpful medical assistant good at reading laboratory reports. Answer the questions.
Question: {question}
"""
PDF_TEMPLATE = """
You are a helpful medical assistant good at reading laboratory reports.
Please explain this laboratory report in simple terms.

Here are the extracted text from the PDF:
{pdf_content}
"""
IMAGE_INSTRUCTIONS = """
You are a helpful medical assistant good at reading medical images.
Please describe this medical image in simple terms.
"""

class ImageDescription(BaseModel):
    description: str = Field(None, description = "Description of the image")


def get_model():
    model = ChatOpenAI(model=QA_MODEL, api_key=os.environ["OPENAI_API_KEY"])
    return model


def extract_text_from_pdf(pdf_path: str) -> str:
    pdf_text = ""
    # read the pdf
    with open(pdf_path, 'rb') as file_:
        reader = PyPDF2.PdfReader(file_)
        # extract the text
        for page_num in range(len(reader.pages)):
            page = reader.pages[page_num]
            pdf_text += page.extract_text()

    final_text = pdf_text.strip().replace("\n", "")

    return final_text


def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')


def streaming_pdf_explanation(pdf_path: str):
    # extract the pdf text
    pdf_text = extract_text_from_pdf(pdf_path)
    
    # modeling
    prompt = ChatPromptTemplate.from_template(PDF_TEMPLATE)
    model = get_model()
    output_parser = StrOutputParser()

    # create the chain
    chain = prompt | model | output_parser

    # get the answer
    return prompt.format(pdf_content=pdf_text), chain.invoke({"pdf_content": pdf_text})


def streaming_question_answering(query_question: str, template: str = COMMON_TEMPLATE):
    prompt = ChatPromptTemplate.from_template(template)
    model = get_model()
    output_parser = StrOutputParser()

    # create the chain
    chain = prompt | model | output_parser

    # get the answer
    return chain.stream({"question": query_question})


def image_description_generator(image_path: str):
    image_data = encode_image(image_path)
    # set up the message
    message = HumanMessage(
        content=[
            {"type": "text", "text": IMAGE_INSTRUCTIONS},
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{image_data}"},
            },
        ],
    )
    # create a structured output
    llm = get_model()
    structured_llm = llm.with_structured_output(ImageDescription)
    # invoke the llm to generatr an query
    invoke_image_query = structured_llm.invoke([message])
    print(message)

    return message, invoke_image_query.description